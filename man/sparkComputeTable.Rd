% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sparkComputeTable.R
\name{sparkComputeTable}
\alias{sparkComputeTable}
\title{This function computes a table from a Spark query and saves it with the specified table name, either as a temporary table or a permanent table}
\usage{
sparkComputeTable(query, tableName, schema = list(), temporary = FALSE)
}
\arguments{
\item{query}{A Spark query or a spark dataframe object representing the data to compute and save.}

\item{tableName}{A string specifying the name of the table to save.}

\item{schema}{A list specifying the schema details for the table. The list may include:
\itemize{
\item \code{catalog}:  The catalog name.
\item \code{schema}:  The schema name.
\item \code{prefix}: (Optional) A prefix to the table name.
}}

\item{temporary}{A logical value indicating whether to create a temporary table (\code{TRUE}) or a permanent table (\code{FALSE}). Defaults to \code{FALSE}.}
}
\value{
\itemize{
\item If \code{temporary = TRUE}, the function returns a registered temporary table in Spark
\item If \code{temporary = FALSE}, the function writes the table to the specified schema
}
}
\description{
This function computes a table from a Spark query and saves it with the specified table name, either as a temporary table or a permanent table
}
